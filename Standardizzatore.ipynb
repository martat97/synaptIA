{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e610879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARDIZZATORE ##\n",
    "\n",
    "#FASI\n",
    "#1. LETTURA estensione\n",
    "#2. TRADUZIONE in JSON\n",
    "\n",
    "\n",
    "#FORMATI DATASET (fonte: https://docs.italia.it/AgID/documenti-in-consultazione/lg-opendata-docs/it/bozza/allegato-b-standard-di-riferimento-e-formati-aperti.html)\n",
    "\n",
    "#!! PRINCIPALI !!\n",
    "##Formati aperti per i dati\n",
    "#CSV (Comma Separated Values)\n",
    "#JSON (JavaScript Object Notation)\n",
    "#XML (eXtensible Markup Language)\n",
    "#XLSX (Excel)\n",
    "#!!\n",
    "\n",
    "\n",
    "##Formati aperti pi√π diffusi per i dati geografici\n",
    "#Shapefile\n",
    "#KML\n",
    "#GeoJSON\n",
    "#GML (Geography Markup Language)\n",
    "#GeoPackage\n",
    "\n",
    "##Formati aperti per i documenti\n",
    "#ODF (Open Document Format)\n",
    "#PDF\n",
    "#Akoma Ntoso\n",
    "\n",
    "##Formati per dati meteorologici\n",
    "#BUFR (Binary Universal Form for the Representation of meteorological data)\n",
    "#NetCDF (Network Common Data Form)\n",
    "#ASCII (American Standard Code for Information Interchange)\n",
    "#Avvisi Meteo: \n",
    "#CAP (Common Alerting Protocol), RSS (Really Simple Syndication)/Atom\n",
    "#Radar: \n",
    "#HDF5 (Hierarchical Data Format)\n",
    "#Modello NWP (Numerical weather prediction): \n",
    "#GRIB (General Representation of fields In Binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace16c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract(file_path):\n",
    "    root, extension = os.path.splitext(file)\n",
    "    columns_list = []\n",
    "    if (extension == '.csv'):\n",
    "        columns_list = extract_csv(file_path)      \n",
    "    elif (extension == '.xml'):\n",
    "        columns_list = extract_xml(file_path) \n",
    "    elif (extension == '.json'):\n",
    "        columns_list = extract_json(file_path)\n",
    "    elif (extension == '.xlsx'):\n",
    "        columns_list = extract_excel(file_path)      \n",
    "        \n",
    "    return columns_list\n",
    "        \n",
    "def extract_csv(file_path):\n",
    "    data = pd.read_csv(file_path, encoding='latin1')         \n",
    "    columns_list = [col for col in data.columns.tolist() if not col.startswith('Unnamed')]\n",
    "    return columns_list\n",
    "    \n",
    "def extract_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Filtra le chiavi con nomi diversi da 'Unnamed'\n",
    "    columns_list = [key for key in data.keys() if not key.startswith('Unnamed')]\n",
    "    return columns_list\n",
    "\n",
    "def extract_excel(file_path):\n",
    "    data = pd.read_excel(file_path)\n",
    "    # Filtra le colonne con nomi diversi da 'Unnamed'\n",
    "    columns_list = [col for col in data.columns.tolist() if not col.startswith('Unnamed')]\n",
    "    return columns_list\n",
    "\n",
    "def extract_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    columns = set()\n",
    "\n",
    "    # esplorazione dell'XML\n",
    "    def explore_xml(element):\n",
    "        nonlocal columns\n",
    "        if not element.tag.startswith('Unnamed'):\n",
    "            columns.add(element.tag)  # Aggiungi il nome del tag come colonna\n",
    "        for child in element:\n",
    "            explore_xml(child)  # Esplora ricorsivamente gli elementi figlio\n",
    "\n",
    "    # Esplora ricorsivamente l'XML per identificare le colonne\n",
    "    explore_xml(root)\n",
    "\n",
    "    columns_list = list(columns)\n",
    "    \n",
    "    return columns_list\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaeaa2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_3812\\34338451.py:21: DtypeWarning: Columns (2,4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "root_directory = 'test dataset clustering'\n",
    "extensions = ['.csv', '.xml', '.json', '.xlsx']\n",
    "directories = [dirc for dirc in os.listdir(root_directory)]\n",
    "#files = [file for file in os.listdir(directory) if file.endswith(tuple(extensions))]\n",
    "\n",
    "# Dizionario per contenere i dati convertiti in JSON\n",
    "datasets_json = {}\n",
    "\n",
    "# Converte ciascun file in un JSON\n",
    "for directory in directories:\n",
    "    category = directory\n",
    "    directory_path = root_directory + \"/\" + directory\n",
    "    files = [file for file in os.listdir(directory_path) if file.endswith(tuple(extensions))]\n",
    "    for file in files:\n",
    "        file_path = directory_path + \"/\" + file\n",
    "        #toglie estensione\n",
    "        dataset_name = os.path.splitext(file)[0]\n",
    "        #print(dataset_name)\n",
    "        #splitta da categoria con simbolo $\n",
    "        #split_name = dataset_name.split('$', 1)\n",
    "        #real_name = split_name[0]\n",
    "        #category = split_name[1]\n",
    "        \n",
    "        columns_list = extract(file_path)\n",
    "        columns_list.insert(0,category)\n",
    "        #print(columns_list[0:10])\n",
    "        # Aggiunge al dizionario JSON\n",
    "        datasets_json[dataset_name] = columns_list\n",
    "        \n",
    "\n",
    "# Esporta il dizionario in formato JSON\n",
    "with open(\"export.json\", \"w\") as outfile:\n",
    "    json.dump(datasets_json, outfile, indent=4,)\n",
    "\n",
    "#print(datasets_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0459c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891ff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b444277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
