{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARDIZZATORE ##\n",
    "\n",
    "#FASI\n",
    "#1. LETTURA estensione\n",
    "#2. TRADUZIONE in JSON\n",
    "\n",
    "\n",
    "#FORMATI DATASET (fonte: https://docs.italia.it/AgID/documenti-in-consultazione/lg-opendata-docs/it/bozza/allegato-b-standard-di-riferimento-e-formati-aperti.html)\n",
    "\n",
    "#!! PRINCIPALI !!\n",
    "##Formati aperti per i dati\n",
    "#CSV (Comma Separated Values)\n",
    "#JSON (JavaScript Object Notation)\n",
    "#XML (eXtensible Markup Language)\n",
    "#XLSX (Excel)\n",
    "#!!\n",
    "\n",
    "\n",
    "##Formati aperti più diffusi per i dati geografici\n",
    "#Shapefile\n",
    "#KML\n",
    "#GeoJSON\n",
    "#GML (Geography Markup Language)\n",
    "#GeoPackage\n",
    "\n",
    "##Formati aperti per i documenti\n",
    "#ODF (Open Document Format)\n",
    "#PDF\n",
    "#Akoma Ntoso\n",
    "\n",
    "##Formati per dati meteorologici\n",
    "#BUFR (Binary Universal Form for the Representation of meteorological data)\n",
    "#NetCDF (Network Common Data Form)\n",
    "#ASCII (American Standard Code for Information Interchange)\n",
    "#Avvisi Meteo: \n",
    "#CAP (Common Alerting Protocol), RSS (Really Simple Syndication)/Atom\n",
    "#Radar: \n",
    "#HDF5 (Hierarchical Data Format)\n",
    "#Modello NWP (Numerical weather prediction): \n",
    "#GRIB (General Representation of fields In Binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2e97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from bson import ObjectId\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c26b6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(max_len, n_sample):\n",
    "    random.seed(0)\n",
    "    # Verifica che il numero di righe di cui fare sample non sia superiore al numero massimo effettivo di righe\n",
    "    actual_n_sample = n_sample\n",
    "    if (n_sample > max_len):\n",
    "        actual_n_sample = max_len\n",
    "\n",
    "    # Genera una lista di numeri casuali distinti nell'intervallo specificato\n",
    "    row_list = random.sample(range(0, max_len), actual_n_sample)\n",
    "\n",
    "    # Stampare la lista di numeri casuali distinti\n",
    "    return row_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ace16c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_path, n_sample):\n",
    "    sample = None\n",
    "    root, extension = os.path.splitext(file_path)\n",
    "    if (extension == '.csv'):\n",
    "        sample = extract_csv(file_path, n_sample)      \n",
    "    #elif (extension == '.xml'):\n",
    "    #    json_item = extract_xml(file_path) \n",
    "    #elif (extension == '.json'):\n",
    "    #    sample = extract_json(file_path, n_sample)\n",
    "    elif (extension == '.xlsx'):\n",
    "        sample = extract_excel(file_path, n_sample)      \n",
    "        \n",
    "    return sample\n",
    "        \n",
    "def extract_csv(file_path, n_sample):\n",
    "    data = pd.read_csv(file_path, encoding='latin1')  \n",
    "    row_sampled = random_sampling(len(data),n_sample)\n",
    "    sample_data = data.loc[row_sampled]\n",
    "    return sample_data\n",
    "    \n",
    "#def extract_json(file_path, n_sample):\n",
    "#    with open(file_path, 'r') as file:\n",
    "#        data = json.load(file)\n",
    "#    return data\n",
    "\n",
    "def extract_excel(file_path, n_sample):\n",
    "    data = pd.read_excel(file_path)\n",
    "    row_sampled = random_sampling(len(data),n_sample)\n",
    "    sample_data = data.loc[row_sampled]   \n",
    "    return sample_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "68415c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi verifica se la lista è numerica nonostante la presenza di stringhe\n",
    "def is_numeric_list(lst):\n",
    "    try:\n",
    "        # Prova a convertire ogni elemento in float\n",
    "        float_values = [float(element) for element in lst]\n",
    "        return True\n",
    "    except ValueError:\n",
    "        # Se la conversione in float genera un errore, la lista non è completamente numerica\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "#identifico il tipo di variabile fra:\n",
    "#numerica discreta\n",
    "#numerica continua\n",
    "#categorica (parole per le categorie) o testuale (solo testi diversi)?\n",
    "\n",
    "def variable_type_detector(variable):\n",
    "    vtype = \"undefined\"\n",
    "    #è numerica\n",
    "    if(pd.api.types.is_numeric_dtype(variable)):\n",
    "        #conta ripetizioni di valori\n",
    "        unique_counter = variable.nunique()\n",
    "        #al massimo 8 categorie (esempio)\n",
    "        max_counter = 8 \n",
    "        if (unique_counter <= max_counter):\n",
    "            vtype = \"categorical numerical\"\n",
    "        else:\n",
    "            vtype = \"continuous numerical\"\n",
    "    #è testuale\n",
    "    else:\n",
    "        #conta ripetizioni di valori\n",
    "        unique_counter = variable.nunique()\n",
    "        #al massimo 8 categorie (esempio)\n",
    "        max_counter = 8 \n",
    "        if (unique_counter <= max_counter):\n",
    "            vtype = \"categorical textual\"\n",
    "        else:\n",
    "            vtype = \"text\"\n",
    "            \n",
    "    return vtype\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a4585be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Carica il file CSV\n",
    "file_path = 'kaggle_datasets/classification/coffee_maker.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "variable_type_detector(df['rating'])\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4edbb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_node(file_name, sample_data):\n",
    "    #default values\n",
    "    file_elements = file_name.split(\".\")\n",
    "    extension_type = \"undefined\"\n",
    "    features = []\n",
    "    n_features = 0\n",
    "    \n",
    "    if (file_elements[1] in ['csv', 'xlsx']):\n",
    "        extension_type = \"tabular\"\n",
    "        n_features = len(sample_data.columns)\n",
    "        features = [\n",
    "        {\n",
    "            \"feature_name\": col,\n",
    "            \"feature_datatype\": sample_data[col].dtype.name,\n",
    "            \"feature_type\": variable_type_detector(sample_data[col]),\n",
    "            \"elements_sampled\": sample_data[col].tolist()\n",
    "        }\n",
    "        for col in sample_data.columns\n",
    "            \n",
    "            \n",
    "    ]   \n",
    "    elif (file_elements[1] in ['jpg', 'png']):\n",
    "        extension_type = \"image\"   \n",
    "    \n",
    "    \n",
    "    new_file = {\n",
    "        \"file_name\": file_elements[0],\n",
    "        \"file_extension\": file_elements[1],\n",
    "        \"file_type\": extension_type,\n",
    "        \"n_features\": n_features,\n",
    "        \"features\": features\n",
    "    }\n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fdac234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_folders(root, subfolders_limit, files_limit, new_dataset_node, subfolder_count=0):\n",
    "#mi prende eventuali files, i primi 10\n",
    "    for current_root, dirs, files in os.walk(root):\n",
    "        for file in files[0:files_limit]:\n",
    "            file_path = os.path.join(current_root, file)\n",
    "            n_sample = 100\n",
    "            file_sample = extract(file_path, n_sample)\n",
    "            if file_sample is not None:\n",
    "                new_file = create_file_node(file, file_sample)\n",
    "                new_dataset_node[\"files\"].append(new_file)\n",
    "                print(file_path)\n",
    "                \n",
    "        #se c'è una sottocartella, \"scava\" ad albero, limitando il numero di sottocartelle da esaminare\n",
    "        # Chiamata ricorsiva per le prime massime sottocartelle\n",
    "        if subfolder_count >= subfolders_limit:\n",
    "            break\n",
    "            \n",
    "        for subfolder in dirs:\n",
    "            new_root = os.path.join(current_root, subfolder)\n",
    "            subfolder_count = subfolder_count + 1\n",
    "            navigate_folders(new_root, subfolders_limit, files_limit, subfolder_count)\n",
    "            # Verifica se abbiamo raggiunto il limite delle sottocartelle\n",
    "            if subfolder_count >= subfolders_limit:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4f470294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_navigate/classification/atis_intents\\atis_intents.csv\n",
      "test_navigate/classification/atis_intents\\atis_intents_test.csv\n",
      "test_navigate/classification/atis_intents\\atis_intents_train.csv\n",
      "test_navigate/classification/bill_authentication\\bill_authentication.csv\n",
      "test_navigate/classification/birds\\birds.csv\n",
      "test_navigate/classification/bodyPerformance\\bodyPerformance.csv\n",
      "test_navigate/classification/breast-cancer-data\\breast-cancer-data.csv\n"
     ]
    }
   ],
   "source": [
    "#Navigation\n",
    "\n",
    "#Directory\n",
    "root_directory = 'test_navigate'\n",
    "extensions = ['.csv', '.json', '.xlsx']\n",
    "directories = [dirc for dirc in os.listdir(root_directory)]\n",
    "#files = [file for file in os.listdir(directory) if file.endswith(tuple(extensions))]\n",
    "\n",
    "# Json final\n",
    "datasets_json = {}\n",
    "\n",
    "\n",
    "# Converte ciascun file in un JSON\n",
    "for directory in directories:\n",
    "    category = directory \n",
    "    directory_path = root_directory + \"/\" + directory\n",
    "    #each folder is the name of the dataset\n",
    "    datasets = [dataset for dataset in os.listdir(directory_path)]\n",
    "    #in ciascuna cartella del dataset, posso aspettarmi di tutto, cartelle, files etc.. come faccio?\n",
    "    #possibile soluzione: prendo alpiù 5 cartelle e alpiù 10 files, nelle cartelle scavo ad albero in 1-2 livelli massimi,\n",
    "    #poi mi fermo e inserisco max 10 files nella struttura\n",
    "    for dataset in datasets:\n",
    "        dataset_path = root_directory + \"/\" + directory + \"/\" + dataset\n",
    "        new_dataset_node = {\"_id\": dataset, \"label\": category, \"files\": []}\n",
    "        navigate_folders(dataset_path, 5, 10, new_dataset_node)\n",
    "        \n",
    "        json_data = json.dumps(new_dataset_node, indent=2)\n",
    "        with open(\"output \" + dataset + \".json\", \"w\") as json_file:\n",
    "            json_file.write(json_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30caa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de290da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf3cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb0459c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8185 entries, 0 to 8184\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                                      Non-Null Count  Dtype  \n",
      "---  ------                                                      --------------  -----  \n",
      " 0   Project Geographic District                                 8185 non-null   int64  \n",
      " 1   Project Building Identifier                                 8185 non-null   object \n",
      " 2   Project School Name                                         8185 non-null   object \n",
      " 3   Project Type                                                8185 non-null   object \n",
      " 4   Project Description                                         8185 non-null   object \n",
      " 5   Project Phase Name                                          8184 non-null   object \n",
      " 6   Project Status Name                                         8185 non-null   object \n",
      " 7   Project Phase Actual Start Date                             8185 non-null   object \n",
      " 8   Project Phase Planned End Date                              8185 non-null   object \n",
      " 9   Project Phase Actual End Date                               6027 non-null   object \n",
      " 10  Project Budget Amount                                       8185 non-null   object \n",
      " 11  Final Estimate of Actual Costs Through End of Phase Amount  8181 non-null   float64\n",
      " 12  Total Phase Actual Spending Amount                          8185 non-null   float64\n",
      " 13  DSF Number(s)                                               8185 non-null   object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 895.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Carica il file CSV\n",
    "file_path = 'test dataset clustering/education/capital-project-schedules-and-budgets-1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ottieni i metadati\n",
    "info = df.info()\n",
    "\n",
    "# Visualizza i metadati\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e891ff2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Geographic District                                     32\n",
      "Project Building Identifier                                   1196\n",
      "Project School Name                                           1483\n",
      "Project Type                                                    20\n",
      "Project Description                                           1363\n",
      "Project Phase Name                                               8\n",
      "Project Status Name                                              3\n",
      "Project Phase Actual Start Date                               1069\n",
      "Project Phase Planned End Date                                1168\n",
      "Project Phase Actual End Date                                  888\n",
      "Project Budget Amount                                         3613\n",
      "Final Estimate of Actual Costs Through End of Phase Amount    5730\n",
      "Total Phase Actual Spending Amount                            5060\n",
      "DSF Number(s)                                                 3554\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = df.nunique()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b444277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
