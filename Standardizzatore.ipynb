{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARDIZZATORE ##\n",
    "\n",
    "#FASI\n",
    "#1. LETTURA estensione\n",
    "#2. TRADUZIONE in JSON\n",
    "\n",
    "\n",
    "#FORMATI DATASET (fonte: https://docs.italia.it/AgID/documenti-in-consultazione/lg-opendata-docs/it/bozza/allegato-b-standard-di-riferimento-e-formati-aperti.html)\n",
    "\n",
    "#!! PRINCIPALI !!\n",
    "##Formati aperti per i dati\n",
    "#CSV (Comma Separated Values)\n",
    "#JSON (JavaScript Object Notation)\n",
    "#XML (eXtensible Markup Language)\n",
    "#XLSX (Excel)\n",
    "#!!\n",
    "\n",
    "\n",
    "##Formati aperti più diffusi per i dati geografici\n",
    "#Shapefile\n",
    "#KML\n",
    "#GeoJSON\n",
    "#GML (Geography Markup Language)\n",
    "#GeoPackage\n",
    "\n",
    "##Formati aperti per i documenti\n",
    "#ODF (Open Document Format)\n",
    "#PDF\n",
    "#Akoma Ntoso\n",
    "\n",
    "##Formati per dati meteorologici\n",
    "#BUFR (Binary Universal Form for the Representation of meteorological data)\n",
    "#NetCDF (Network Common Data Form)\n",
    "#ASCII (American Standard Code for Information Interchange)\n",
    "#Avvisi Meteo: \n",
    "#CAP (Common Alerting Protocol), RSS (Really Simple Syndication)/Atom\n",
    "#Radar: \n",
    "#HDF5 (Hierarchical Data Format)\n",
    "#Modello NWP (Numerical weather prediction): \n",
    "#GRIB (General Representation of fields In Binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from bson import ObjectId\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(max_len, n_sample):\n",
    "    random.seed(0)\n",
    "    # Verifica che il numero di righe di cui fare sample non sia superiore al numero massimo effettivo di righe\n",
    "    actual_n_sample = n_sample\n",
    "    if (n_sample > max_len):\n",
    "        actual_n_sample = max_len\n",
    "\n",
    "    # Genera una lista di numeri casuali distinti nell'intervallo specificato\n",
    "    row_list = random.sample(range(0, max_len), actual_n_sample)\n",
    "\n",
    "    # Stampare la lista di numeri casuali distinti\n",
    "    return row_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace16c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_path, n_sample): \n",
    "    data = None\n",
    "    nrow = 0\n",
    "    root, extension = os.path.splitext(file_path)\n",
    "    new_sample = None\n",
    "    try:\n",
    "        if (extension == '.csv'):\n",
    "            data = pd.read_csv(file_path, encoding='latin1') \n",
    "            #conversione da effettuare perchè json ha problemi con colonne timestamp  \n",
    "            new_sample = sample(data, n_sample)\n",
    "            nrow = len(data)  \n",
    "            #for col in new_sample.columns:\n",
    "            #    if (pd.api.types.is_datetime64_any_dtype(new_sample[col])):\n",
    "            #        new_sample[col] = new_sample[col].astype(str)\n",
    "        elif (extension == '.xlsx'):\n",
    "            data = pd.read_excel(file_path) \n",
    "            #conversione da effettuare perchè json ha problemi con colonne timestam                \n",
    "            new_sample = sample(data, n_sample)  \n",
    "            nrow = len(data)   \n",
    "            #for col in new_sample.columns:\n",
    "            #    if (pd.api.types.is_datetime64_any_dtype(new_sample[col])):\n",
    "            #        new_sample[col] = new_sample[col].astype(str)\n",
    "    except Exception as e: #se ha problemi a leggere file tabulari sbagliati\n",
    "        data = None\n",
    "        # Ignora l'eccezione e continua senza stampare l'errore\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    return new_sample, nrow\n",
    "        \n",
    "def sample(data, n_sample):\n",
    "    row_sampled = random_sampling(len(data),n_sample)\n",
    "    sample_data = data.loc[row_sampled]\n",
    "    return sample_data\n",
    "    \n",
    "#def extract_json(file_path, n_sample):\n",
    "#    with open(file_path, 'r') as file:\n",
    "#        data = json.load(file)\n",
    "#    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68415c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi verifica se la lista è numerica nonostante la presenza di stringhe\n",
    "def is_numeric_variable(lst):\n",
    "    try:\n",
    "        # Prova a convertire ogni elemento in float\n",
    "        float_values = [float(element) for element in lst]\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # Se la conversione in float genera un errore, la lista non è completamente numerica\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "#identifico il tipo di variabile fra:\n",
    "#numerica discreta\n",
    "#numerica continua\n",
    "#categorica (parole per le categorie) o testuale (solo testi diversi)?\n",
    "\n",
    "def variable_type_detector(variable):\n",
    "    vtype = \"\"\n",
    "    #è numerica (tipo int, o stringhe che rappresentano numeri)\n",
    "    if(pd.api.types.is_numeric_dtype(variable) | is_numeric_variable(variable)):\n",
    "        #conta ripetizioni di valori\n",
    "        unique_counter = variable.nunique()\n",
    "        #al massimo 15 categorie (esempio)\n",
    "        max_counter = 15 \n",
    "        if (unique_counter <= max_counter):\n",
    "            vtype = \"categorical numerical\"\n",
    "        else:\n",
    "            vtype = \"continuous numerical\"\n",
    "    #è testuale\n",
    "    else:\n",
    "        #conta ripetizioni di valori\n",
    "        unique_counter = variable.nunique()\n",
    "        #al massimo 15 categorie (esempio)\n",
    "        max_counter = 15 \n",
    "        if (unique_counter <= max_counter):\n",
    "            vtype = \"categorical textual\"\n",
    "        else:\n",
    "            vtype = \"text\"\n",
    "            \n",
    "    return vtype\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_node(file_name, sample_data, nrow):\n",
    "    #default values\n",
    "    file_elements = file_name.split(\".\")\n",
    "    extension_type = \"undefined\"\n",
    "    features = []\n",
    "    n_features = 0\n",
    "    \n",
    "    if (file_elements[1] in ['csv', 'xlsx']):\n",
    "        extension_type = \"tabular\"\n",
    "        n_features = len(sample_data.columns)\n",
    "        #controlla se è time stamp la feature, la converte in stringa, altrimenti json non va\n",
    "          \n",
    "        \n",
    "        features = [\n",
    "        {\n",
    "            \"feature_name\": col,\n",
    "            \"feature_datatype\": sample_data[col].dtype.name,\n",
    "            \"feature_type\": variable_type_detector(sample_data[col]),\n",
    "            \"elements_sampled\": sample_data[col].tolist()\n",
    "        }\n",
    "        for col in sample_data.columns         \n",
    "            \n",
    "    ]   \n",
    "    elif (file_elements[1] in ['jpg', 'png']):\n",
    "        extension_type = \"image\"   \n",
    "    \n",
    "    \n",
    "    new_file = {\n",
    "        \"file_name\": file_elements[0],\n",
    "        \"file_extension\": file_elements[1],\n",
    "        \"file_type\": extension_type,\n",
    "        \"n_istances\": nrow,\n",
    "        \"n_features\": n_features,\n",
    "        \"features\": features\n",
    "    }\n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_folders(root, subfolders_limit, files_limit, new_dataset_node, subfolder_count=0):\n",
    "#mi prende eventuali files, i primi 10\n",
    "    for current_root, dirs, files in os.walk(root):\n",
    "        for file in files[0:files_limit]:\n",
    "            file_path = os.path.join(current_root, file)\n",
    "            n_sample = 100\n",
    "            result_sample = extract(file_path, n_sample)\n",
    "            file_sample = result_sample[0]\n",
    "            nrow = result_sample[1]\n",
    "            if file_sample is not None:\n",
    "                new_file = create_file_node(file, file_sample, nrow)\n",
    "                new_dataset_node[\"files\"].append(new_file)\n",
    "                #print(file)\n",
    "                \n",
    "                \n",
    "        #se c'è una sottocartella, \"scava\" ad albero, limitando il numero di sottocartelle da esaminare\n",
    "        # Chiamata ricorsiva per le prime massime sottocartelle\n",
    "        if subfolder_count >= subfolders_limit:\n",
    "            break\n",
    "            \n",
    "        for subfolder in dirs:\n",
    "            new_root = os.path.join(current_root, subfolder)\n",
    "            subfolder_count = subfolder_count + 1\n",
    "            navigate_folders(new_root, subfolders_limit, files_limit, new_dataset_node, subfolder_count)\n",
    "            # Verifica se abbiamo raggiunto il limite delle sottocartelle\n",
    "            if subfolder_count >= subfolders_limit:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f470294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigation\n",
    "\n",
    "#Directory\n",
    "root_directory = 'kaggle_datasets'\n",
    "output_root_directory = 'datapoints'\n",
    "extensions = ['.csv', '.json', '.xlsx']\n",
    "directories = [dirc for dirc in os.listdir(root_directory)]\n",
    "#files = [file for file in os.listdir(directory) if file.endswith(tuple(extensions))]\n",
    "\n",
    "# Json final\n",
    "datasets_json = {}\n",
    "# Converte ciascun file in un JSON\n",
    "for directory in directories:\n",
    "    category = directory \n",
    "    directory_path = root_directory + \"/\" + directory\n",
    "    #each folder is the name of the dataset\n",
    "    datasets = [dataset for dataset in os.listdir(directory_path)]\n",
    "    #in ciascuna cartella del dataset, posso aspettarmi di tutto, cartelle, files etc.. come faccio?\n",
    "    #possibile soluzione: prendo alpiù 5 cartelle e alpiù 10 files, nelle cartelle scavo ad albero in 1-2 livelli massimi,\n",
    "    #poi mi fermo e inserisco max 10 files nella struttura\n",
    "    for dataset in datasets:\n",
    "        dataset_path = root_directory + \"/\" + directory + \"/\" + dataset\n",
    "        new_dataset_node = {\"_id\": dataset, \"label\": category, \"files\": []}\n",
    "        navigate_folders(dataset_path, 5, 10, new_dataset_node)\n",
    "        \n",
    "        json_data = json.dumps(new_dataset_node, indent=2, default=str)\n",
    "        json_path = output_root_directory  + \"/\" + directory + \"/\"\n",
    "        with open( json_path + dataset + \".json\", \"w\") as json_file:          \n",
    "            json_file.write(json_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0459c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il file CSV\n",
    "file_path = 'kaggle_datasets/clustering/customer-segmentation-dataset/Online Retail.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Ottieni i metadati\n",
    "info = df.info()\n",
    "\n",
    "# Visualizza i metadati\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57bd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b444277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
