{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298f6833",
   "metadata": {},
   "source": [
    "## A. Cosa estraggo dai dati e In che struttura posso salvare i dati?\n",
    "\n",
    "#### Nome dataset\n",
    "#### Nomi features (usati per identificare)\n",
    "#### Tipo features: (numerici (int, double..), stringhe, immagini (jpg, bmp etc..), audio, video)\n",
    "#### Contenuto dati (estratto randomicamente, tot righe)\n",
    "#### Etc...\n",
    "\n",
    "### Possibile soluzione:\n",
    "\n",
    "### JSON: { nomedataset1 -> {nome_feature1, {tipo_feature, [el1, el2, el3, el4, el5] }, feature2, .... } , dataset2, ....}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395d38f",
   "metadata": {},
   "source": [
    "## B. Caratteristiche utili per distinguere le tecniche ML\n",
    "\n",
    "#### 1. Classificazione:\n",
    "##### I dataset con problemi di classificazione presentano la caratteristica di una colonna che contenga le categorie da predirre. Questa colonna nei dataset \"tende\" (poichè non è sempre così) a chiamarsi: label/target/class/type, e \"tende\" ad essere l'ultima colonna del dataset, o l'ultima categorica del dataset. La distinzione tra binario e multiclass è più semplice, nel senso che basta identificare il numero di categorie della colonna target in questione,  è più costoso capirlo in presenza di big data e dovrebbe essere fatta bene una selezione random di righe nel dataset. PROBLEMA: Identificare la colonna target del dataset. \n",
    "#### 2. Regressione:\n",
    "##### Nel caso della regressione, è possibile applicarla con diverse variabili tipicamente numeriche, dunque va ricercata questa caratteristica. Spesso la regressione assume una distribuzione normale dei dati, quindi con opportuine stime si potrebbe determinare se le variabili numeriche, nel campione delle righe, seguano effettivamente una distribuzione normale oppure no. Se è possibile individuare la variabile dipendente y, magari tramite nome feature o altre informazioni esterne, allora è possibile anche determinare se esiste una relazione lineare tra quella variabile e le altre indipendenti. Vanno valutate anche altre caratteristiche adatte nella regressione, come la varianza della variabile dipendente, eventuali outliers etc.. \n",
    "#### 3. Computer Vision:\n",
    "##### I dataset con task di computer vision presentano tipi di dati di formato immagine (.jpg, .png etc..), soprattutto \"tante\" immagini. Per assegnare questa categoria bisogna andare alla ricerca di questo tipo di dato, oltretutto tendono ad essere categorizzata in cartella train e test, alle volte anche con i label assegnati, questo fattore può rafforzare l'ipotesi di un'insieme di dati adatto a computer vision. Va' valutata anche la dimensione delle immagini, poichè se troppo piccole o troppo grandi possono contenere pochi/troppi dettagli per l'applicazione dell'algoritmo.\n",
    "#### 4. NLP:\n",
    "##### I dataset con task di natural language processing presentano come variabile input testi in formato testo/stringa. Queste variabili formato stringa possono tuttavia essere anche categoriche. Va' fatta distinzione tra variabile contenente un testo, e una variabile contenente diverse categorie\n",
    "#### 5. Clustering: \n",
    "##### Forse il più difficile. Per l'applicazione del clustering, essendo un problema unsupervised, possiamo utilizzare variabili di tipo variegato, quindi più che osservare i tipi, dovremmo vedere se si nota effettivamente la presenza di pattern/comportamenti simili nei dati, ovvero che abbiano una tendenza a raggrupparsi, questo rafforzerebbe l'ipotesi di applicazione clustering.\n",
    "#### 6. Time Series: \n",
    "##### Per l'utilizzo di serie temporali, va ricercata la variabile che rappresenta il tempo in date, o secondi, o altre unità di misura in cui posso effettuare studi temporali in generale, e soprattutto di misurazioni effettuate a intervalli regolari di tempo.\n",
    "#### 7. GAN:\n",
    "##### Sono tecniche utilizzate per la generazione di dati come immagini, video, audio o anche dati tabulari. Nel caso delle immagini andrebbero utilizzate in dataset con poche immagini, o immagini di bassa qualità, nel caso di dati tabulari quando non ne ho a sufficienza oppure sono mancanti. Andrebbe fatta un'analisi su questo aspetto per valutare se possa essere utile utilizzare tecniche generative.\n",
    "#### 8. PCA:\n",
    "##### Tecnica utile alla riduzione di dimensioni, quindi utilizzabile in una presenza ampia di variabili in un dataset, queste variabili oltretutto se fortemente correlate, rafforzano l'ipotesi dell'utilizzo di pca. Utile anche la presenza di dati rumorosi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9606b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202 entries, 0 to 201\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   Countries and areas                      202 non-null    object \n",
      " 1   Latitude                                 202 non-null    float64\n",
      " 2   Longitude                                202 non-null    float64\n",
      " 3   OOSR_Pre0Primary_Age_Male                202 non-null    int64  \n",
      " 4   OOSR_Pre0Primary_Age_Female              202 non-null    int64  \n",
      " 5   OOSR_Primary_Age_Male                    202 non-null    int64  \n",
      " 6   OOSR_Primary_Age_Female                  202 non-null    int64  \n",
      " 7   OOSR_Lower_Secondary_Age_Male            202 non-null    int64  \n",
      " 8   OOSR_Lower_Secondary_Age_Female          202 non-null    int64  \n",
      " 9   OOSR_Upper_Secondary_Age_Male            202 non-null    int64  \n",
      " 10  OOSR_Upper_Secondary_Age_Female          202 non-null    int64  \n",
      " 11  Completion_Rate_Primary_Male             202 non-null    int64  \n",
      " 12  Completion_Rate_Primary_Female           202 non-null    int64  \n",
      " 13  Completion_Rate_Lower_Secondary_Male     202 non-null    int64  \n",
      " 14  Completion_Rate_Lower_Secondary_Female   202 non-null    int64  \n",
      " 15  Completion_Rate_Upper_Secondary_Male     202 non-null    int64  \n",
      " 16  Completion_Rate_Upper_Secondary_Female   202 non-null    int64  \n",
      " 17  Grade_2_3_Proficiency_Reading            202 non-null    int64  \n",
      " 18  Grade_2_3_Proficiency_Math               202 non-null    int64  \n",
      " 19  Primary_End_Proficiency_Reading          202 non-null    int64  \n",
      " 20  Primary_End_Proficiency_Math             202 non-null    int64  \n",
      " 21  Lower_Secondary_End_Proficiency_Reading  202 non-null    int64  \n",
      " 22  Lower_Secondary_End_Proficiency_Math     202 non-null    int64  \n",
      " 23  Youth_15_24_Literacy_Rate_Male           202 non-null    int64  \n",
      " 24  Youth_15_24_Literacy_Rate_Female         202 non-null    int64  \n",
      " 25  Birth_Rate                               202 non-null    float64\n",
      " 26  Gross_Primary_Education_Enrollment       202 non-null    float64\n",
      " 27  Gross_Tertiary_Education_Enrollment      202 non-null    float64\n",
      " 28  Unemployment_Rate                        202 non-null    float64\n",
      "dtypes: float64(6), int64(22), object(1)\n",
      "memory usage: 45.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Carica il file CSV\n",
    "file_path = 'test dataset clustering/education/Global_Education.csv'\n",
    "df = pd.read_csv(file_path, encoding='latin')\n",
    "\n",
    "# Ottieni i metadati\n",
    "info = df.info()\n",
    "\n",
    "# Visualizza i metadati\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7884e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Project Geographic District   \\\n",
      "count                   8185.000000   \n",
      "mean                      17.648259   \n",
      "std                        9.419492   \n",
      "min                        1.000000   \n",
      "25%                       10.000000   \n",
      "50%                       19.000000   \n",
      "75%                       26.000000   \n",
      "max                       32.000000   \n",
      "\n",
      "       Final Estimate of Actual Costs Through End of Phase Amount  \\\n",
      "count                                       8.181000e+03            \n",
      "mean                                        1.185590e+06            \n",
      "std                                         6.300406e+06            \n",
      "min                                         0.000000e+00            \n",
      "25%                                         1.841900e+04            \n",
      "50%                                         8.030900e+04            \n",
      "75%                                         2.640000e+05            \n",
      "max                                         1.150066e+08            \n",
      "\n",
      "       Total Phase Actual Spending Amount  \n",
      "count                        8.185000e+03  \n",
      "mean                         4.091091e+05  \n",
      "std                          3.255846e+06  \n",
      "min                          0.000000e+00  \n",
      "25%                          0.000000e+00  \n",
      "50%                          6.762000e+03  \n",
      "75%                          7.939600e+04  \n",
      "max                          7.934706e+07  \n"
     ]
    }
   ],
   "source": [
    "basic_statistics = df.describe()\n",
    "print(basic_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ebffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
